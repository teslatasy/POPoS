# Copyright (c) OpenMMLab. All rights reserved.
import torch
import torch.nn as nn

import geomloss
from ..builder import LOSSES

# # #-------------2023-04-23------------
@LOSSES.register_module()
class HuberLoss(nn.Module):
    """huber loss for heatmaps.

    Args:
        use_target_weight (bool): Option to use weighted MSE loss.
            Different joint types may have different target weights.
        loss_weight (float): Weight of the loss. Default: 1.0.
    """

    def __init__(self, use_target_weight=False, loss_weight=1., delta=1.0):
        super().__init__()
        self.use_target_weight = use_target_weight
        self.loss_weight = loss_weight
        self.delta = delta
    
    def criterion(self, pred, target):
        """Criterion of huber. """
        huber_mse = 0.5*(target-pred)**2
        huber_mae = self.delta * (torch.abs(target - pred) - 0.5 * self.delta)
        return torch.where(torch.abs(target - pred) <= self.delta, huber_mse, huber_mae)

    def forward(self, output, target, target_weight):
        """Forward function."""
        # import pdb 
        # pdb.set_trace()

        batch_size = output.size(0)
        num_joints = output.size(1)

        heatmaps_pred = output.reshape(
            (batch_size, num_joints, -1)).split(1, 1)
        heatmaps_gt = target.reshape((batch_size, num_joints, -1)).split(1, 1)

        loss = 0.

        for idx in range(num_joints):
            heatmap_pred = heatmaps_pred[idx].squeeze(1)
            heatmap_gt = heatmaps_gt[idx].squeeze(1)
            # target_weight2 = torch.where( heatmap_gt > 0.5, 1.0, 0.0) ##-----------------
            if self.use_target_weight:
                loss_joint = self.criterion(heatmap_pred, heatmap_gt)
                loss_joint = loss_joint * target_weight[:, idx] 
                # loss_joint = loss_joint * target_weight2 ##-----------------
                loss += loss_joint.mean()
            else:
                loss += self.criterion(heatmap_pred, heatmap_gt)

        return loss / num_joints * self.loss_weight

from functools import reduce

from operator import mul
def flat_softmax(inp):
    """Compute the softmax with all but the first two tensor dimensions combined."""

    orig_size = inp.size()
    flat = inp.view(-1, reduce(mul, orig_size[1:]))
    flat = torch.nn.functional.softmax(flat, -1)
    return flat.view(*orig_size)

def _kl(p, q, ndims):
    eps = 1e-24
    unsummed_kl = p * ((p + eps).log() - (q + eps).log())
    kl_values = reduce(lambda t, _: t.sum(-1, keepdim=False), range(ndims), unsummed_kl)
    return kl_values

def _js(p, q, ndims):
    m = 0.5 * (p + q)
    return 0.5 * _kl(p, m, ndims) + 0.5 * _kl(q, m, ndims)

def _divergence_reg_losses(heatmaps, gauss, divergence):
    ndims=heatmaps.dim() -1
    # ndims = mu_t.size(-1)
    # assert heatmaps.dim() == ndims + 2, 'expected heatmaps to be a {}D tensor'.format(ndims + 2)
    # assert heatmaps.size()[:-ndims] == mu_t.size()[:-1]

    # gauss = make_gauss(mu_t, heatmaps.size()[2:], sigma_t)
    #添加了softmax 看下是不是还是nan
    heatmaps=flat_softmax(heatmaps)
    gauss=flat_softmax(gauss)

    divergences = divergence(heatmaps, gauss, ndims)
    return divergences


def js_reg_losses(heatmaps, gauss):
    """Calculate Jensen-Shannon divergences between heatmaps and target Gaussians.

    Args:
        heatmaps (torch.Tensor): Heatmaps generated by the model
        mu_t (torch.Tensor): Centers of the target Gaussians (in normalized units)
        sigma_t (float): Standard deviation of the target Gaussians (in pixels)

    Returns:
        Per-location JS divergences.
    """

    return _divergence_reg_losses(heatmaps, gauss, _js)







    # 兼容geomloss提供的'euclidean'
# 注意：geomloss要求cost func计算两个batch的距离，也即接受(B, N, D)
def cost_func(a, b, p=2, metric='cosine'):
    """ a, b in shape: (B, N, D) or (N, D)
    """ 
    assert type(a)==torch.Tensor and type(b)==torch.Tensor, 'inputs should be torch.Tensor'
    if metric=='euclidean' and p==1:
        return geomloss.utils.distances(a, b)
    elif metric=='euclidean' and p==2:
        return geomloss.utils.squared_distances(a, b)
    else:
        if a.dim() == 3:
            x_norm = a / a.norm(dim=2)[:, :, None]
            y_norm = b / b.norm(dim=2)[:, :, None]
            M = 1 - torch.bmm(x_norm, y_norm.transpose(-1, -2))
        elif a.dim() == 2:
            x_norm = a / a.norm(dim=1)[:, None]
            y_norm = b / b.norm(dim=1)[:, None]
            M = 1 - torch.mm(x_norm, y_norm.transpose(0, 1))
        M = pow(M, p)
        return M


from geomloss import SamplesLoss


# # #-------------2023-04-23------------
@LOSSES.register_module()
class JointsMSELoss(nn.Module):
    """MSE loss for heatmaps.

    Args:
        use_target_weight (bool): Option to use weighted MSE loss.
            Different joint types may have different target weights.
        loss_weight (float): Weight of the loss. Default: 1.0.
    """

    def __init__(self, use_target_weight=False, loss_weight=1.):
        super().__init__()
        self.use_target_weight = use_target_weight
        reduction = 'none' if use_target_weight else 'mean'
        self.criterion = nn.MSELoss(reduction=reduction)
        self.loss_weight = loss_weight


        self.js_weight = 1.0
        self.entreg = .1 # entropy regularization factor for Sinkhorn
        self.p = 2
        self.metric = 'cosine'
        # self.otloss=geomloss.SamplesLoss("sinkhorn", blur=0.05,)
        self.otloss=geomloss.SamplesLoss(
            loss='sinkhorn', p=self.p,
            # 对于p=1或p=2的情形
            cost=geomloss.utils.distances if self.p==1 else geomloss.utils.squared_distances,
            blur=self.entreg**(1/self.p), backend='tensorized')




    def forward(self, output, target, target_weight):
        """Forward function."""
        # import pdb 
        # pdb.set_trace()

        batch_size = output.size(0)
        num_joints = output.size(1)

        heatmaps_pred = output.reshape(
            (batch_size, num_joints, -1)).split(1, 1)
        heatmaps_gt = target.reshape((batch_size, num_joints, -1)).split(1, 1)

        loss = 0.

        for idx in range(num_joints):
            heatmap_pred = heatmaps_pred[idx].squeeze(1)
            heatmap_gt = heatmaps_gt[idx].squeeze(1)
            # target_weight2 = torch.where( heatmap_gt > 0.5, 1.0, 0.0) ##-----------------
            if self.use_target_weight:
                loss_joint = self.criterion(heatmap_pred, heatmap_gt)
                loss_joint = loss_joint * target_weight[:, idx] 
                # print(heatmap_pred.device) #cuda [64, 4096]
                # ot_heamap=heatmap_pred.view(-1,64,64)
                # ot_heamap_gt=heatmap_gt.view(-1,64,64)
                # print(self.otloss(heatmap_pred,heatmap_gt))
                loss_js=self.js_weight*self.otloss(heatmap_pred.cpu(),heatmap_gt.cpu())##add  by xiang
                # loss_joint = loss_joint * target_weight2 ##-----------------
                loss += loss_joint.mean() ##add by xiang
                loss+=loss_js.cuda().mean()
            else:
                # ot_heamap=heatmap_pred.view(-1,64,64)
                # ot_heamap_gt=heatmap_gt.view(-1,64,64)
                loss += self.criterion(heatmap_pred, heatmap_gt)
                loss += self.js_weight*self.otloss(heatmap_pred,heatmap_gt).mean() 
            
                
        return loss / num_joints * self.loss_weight 

        # return loss/ num_joints * self.loss_weight 
@LOSSES.register_module()
class CombinedTargetMSELoss(nn.Module):
    """MSE loss for combined target.
        CombinedTarget: The combination of classification target
        (response map) and regression target (offset map).
        Paper ref: Huang et al. The Devil is in the Details: Delving into
        Unbiased Data Processing for Human Pose Estimation (CVPR 2020).

    Args:
        use_target_weight (bool): Option to use weighted MSE loss.
            Different joint types may have different target weights.
        loss_weight (float): Weight of the loss. Default: 1.0.
    """

    def __init__(self, use_target_weight, loss_weight=1.):
        super().__init__()
        self.criterion = nn.MSELoss(reduction='mean')
        self.use_target_weight = use_target_weight
        self.loss_weight = loss_weight
 

    def forward(self, output, target, target_weight):
        batch_size = output.size(0)
        num_channels = output.size(1)
        heatmaps_pred = output.reshape(
            (batch_size, num_channels, -1)).split(1, 1)
        heatmaps_gt = target.reshape(
            (batch_size, num_channels, -1)).split(1, 1)
        loss = 0.
        num_joints = num_channels // 3
        for idx in range(num_joints):
            heatmap_pred = heatmaps_pred[idx * 3].squeeze()
            heatmap_gt = heatmaps_gt[idx * 3].squeeze()
            offset_x_pred = heatmaps_pred[idx * 3 + 1].squeeze()
            offset_x_gt = heatmaps_gt[idx * 3 + 1].squeeze()
            offset_y_pred = heatmaps_pred[idx * 3 + 2].squeeze()
            offset_y_gt = heatmaps_gt[idx * 3 + 2].squeeze()
            if self.use_target_weight:
                heatmap_pred = heatmap_pred * target_weight[:, idx]
                heatmap_gt = heatmap_gt * target_weight[:, idx]
            # classification loss
            loss += 0.5 * self.criterion(heatmap_pred, heatmap_gt)
            # regression loss
            loss += 0.5 * self.criterion(heatmap_gt * offset_x_pred,
                                         heatmap_gt * offset_x_gt)
            loss += 0.5 * self.criterion(heatmap_gt * offset_y_pred,
                                         heatmap_gt * offset_y_gt)
       
        return loss / num_joints * self.loss_weight
        # return loss / num_joints * self.loss_weight+js_loss/ num_joints * self.loss_weight ###### add by xiang


@LOSSES.register_module()
class JointsOHKMMSELoss(nn.Module):
    """MSE loss with online hard keypoint mining.

    Args:
        use_target_weight (bool): Option to use weighted MSE loss.
            Different joint types may have different target weights.
        topk (int): Only top k joint losses are kept.
        loss_weight (float): Weight of the loss. Default: 1.0.
    """

    def __init__(self, use_target_weight=False, topk=8, loss_weight=1.):
        super().__init__()
        assert topk > 0
        self.criterion = nn.MSELoss(reduction='none')
        self.use_target_weight = use_target_weight
        self.topk = topk
        self.loss_weight = loss_weight

    def _ohkm(self, loss):
        """Online hard keypoint mining."""
        ohkm_loss = 0.
        N = len(loss)
        for i in range(N):
            sub_loss = loss[i]
            _, topk_idx = torch.topk(
                sub_loss, k=self.topk, dim=0, sorted=False)
            tmp_loss = torch.gather(sub_loss, 0, topk_idx)
            ohkm_loss += torch.sum(tmp_loss) / self.topk
        ohkm_loss /= N
        return ohkm_loss

    def forward(self, output, target, target_weight):
        """Forward function."""
        batch_size = output.size(0)
        num_joints = output.size(1)
        if num_joints < self.topk:
            raise ValueError(f'topk ({self.topk}) should not '
                             f'larger than num_joints ({num_joints}).')
        heatmaps_pred = output.reshape(
            (batch_size, num_joints, -1)).split(1, 1)
        heatmaps_gt = target.reshape((batch_size, num_joints, -1)).split(1, 1)

        losses = []
        for idx in range(num_joints):
            heatmap_pred = heatmaps_pred[idx].squeeze(1)
            heatmap_gt = heatmaps_gt[idx].squeeze(1)
            if self.use_target_weight:
                losses.append(
                    self.criterion(heatmap_pred * target_weight[:, idx],
                                   heatmap_gt * target_weight[:, idx]))
            else:
                losses.append(self.criterion(heatmap_pred, heatmap_gt))

        losses = [loss.mean(dim=1).unsqueeze(dim=1) for loss in losses]
        losses = torch.cat(losses, dim=1)

        return self._ohkm(losses) * self.loss_weight
